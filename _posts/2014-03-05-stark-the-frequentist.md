---
layout: post
title: Stark the Frequentist
author: Dav Clark
---
### What is the difference?

This week we read some frequentist critiques of Bayesian methods (and
statistical practice in general!):

> Stark, P. B. (Submitted). Constraints versus Priors. SIAM/ASA Journal on
> Uncertainty Quantification.

> Freedman, D. (1995). Some issues in the foundation of statistics. Foundations
> of Science, 1, 19–83.

And some supplemental reading:

> Freedman, D. A., & Stark, P. B. (2003). What is the chance of an earthquake?
> In F. Mulargia & R. J. Geller (Eds.), Earthquake Science and Seismic Risk
> Reduction (Vol. 32, pp. 201–213). Dordrecht, The Netherlands: Kluwer.

> Stark, P. B., & Tenorio, L. (2010). A primer of frequentist and Bayesian
> inference in inverse problems. In L. T. Biegler, G. Biros, O. Ghattas, M.
> Heinkenschloss, D. Keyes, B. Mallick, … K. Willcox (Eds.), Large Scale Inverse
> Problems and Quantification of Uncertainty. NY: John Wiley and Sons.

<!--more-->

{% include site_vars %}

Ryan made a [nice chart]({{ BASE_PATH }}/materials/2014-03-05-whiteboard.jpeg)
to capture some elements of the discussion. More generally, it seems that
similar concerns arise again: how can we be thoughtful and conscientious about
our science? Neither Bayes nor Fisher & Neyman provide an easy out.

Next week we'll talk about arguments for Bayes.

Some issues that we're thinking about down the road:

 - “Theory” (as Ryan defines it)
 - Non-parametric approaches
 - Example of two bayesians choosing different priors yeilding different
   conclusions (follow Stark reference)
 - Slomanoff induction
 - Proper philosophy of science (e.g., Popper, Kuhn, etc.)
